{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "callbacks.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "zI2_wTjrcw3K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d2b5bad8-7a57-4240-ae7e-d8b7be578298"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "housing = fetch_california_housing()\n",
        "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
        "housing.data, housing.target)\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(\n",
        "X_train_full, y_train_full)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_valid = scaler.transform(X_valid)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "from tensorflow import keras\n",
        "\n",
        "input_ = keras.layers.Input(shape = X_train.shape[1:])\n",
        "hidden1 = keras.layers.Dense(30, activation='relu', name = 'hidden1')(input_)\n",
        "hidden2 = keras.layers.Dense(30, activation='relu', name='hidden2')(hidden1)\n",
        "concat = keras.layers.Concatenate()([input_, hidden2])\n",
        "output = keras.layers.Dense(1)(concat)\n",
        "\n",
        "model = keras.Model(inputs = [input_], outputs= [output])\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vt40yEXkdnQd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer = 'sgd', loss= 'mse')"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kO40CzXmdJSr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint_cb = keras.callbacks.ModelCheckpoint('mymodel.h5', save_best_only=True)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqHIgX85dId5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "fe00b69c-8b4d-4ebc-a17c-fe9bbb616e7d"
      },
      "source": [
        "model.fit(X_train,y_train, validation_data = (X_valid,y_valid), epochs=5, callbacks=[checkpoint_cb])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 1.0026 - val_loss: 0.5901\n",
            "Epoch 2/5\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.7388 - val_loss: 0.7533\n",
            "Epoch 3/5\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.8907 - val_loss: 0.4757\n",
            "Epoch 4/5\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 4.6909 - val_loss: 0.4843\n",
            "Epoch 5/5\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.6601 - val_loss: 0.4508\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f5f74ef3160>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHaj50yZduQj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = keras.models.load_model('mymodel.h5')"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kUqs6u7HeVX7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred =model.predict(X_test)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rlj_N4vPeazh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7a686aa0-1c11-4a8a-ac92-253679fc7ff4"
      },
      "source": [
        "import numpy as np\n",
        "np.mean(keras.losses.mean_squared_error(y_test, y_pred))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.1910644"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nABdU2PiekmP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6d6cea5b-af65-44a2-b43f-cb116ce5bd13"
      },
      "source": [
        "#using EarlyStopping : it interrupts the training, when there is no  improvements on validation loss for a number of epochs defines by\n",
        "#patience parameter\n",
        "\n",
        "# We can use both checkpoint as well as early stopping callbacks to store the best model and interrrupts the training when there is no\n",
        "#improvement\n",
        "\n",
        "earlyStopping = keras.callbacks.EarlyStopping(patience=10, restore_best_weights= True)\n",
        "#restore best Weight parameter restores the best weights after the training ends\n",
        "#there is no need to load_weights again.\n",
        "model.fit(X_train, y_train, validation_data=(X_valid,y_valid), epochs=100, callbacks=[checkpoint_cb, earlyStopping]) "
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.5033 - val_loss: 0.4279\n",
            "Epoch 2/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4222 - val_loss: 0.3957\n",
            "Epoch 3/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.4197 - val_loss: 0.3909\n",
            "Epoch 4/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4999 - val_loss: 0.3818\n",
            "Epoch 5/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4021 - val_loss: 0.3720\n",
            "Epoch 6/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3909 - val_loss: 0.4208\n",
            "Epoch 7/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3728 - val_loss: 0.3579\n",
            "Epoch 8/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3584 - val_loss: 0.3579\n",
            "Epoch 9/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3653 - val_loss: 0.3614\n",
            "Epoch 10/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3469 - val_loss: 0.3430\n",
            "Epoch 11/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3673 - val_loss: 0.3723\n",
            "Epoch 12/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3380 - val_loss: 0.3416\n",
            "Epoch 13/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4562 - val_loss: 0.3367\n",
            "Epoch 14/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3301 - val_loss: 0.3379\n",
            "Epoch 15/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3390 - val_loss: 0.3298\n",
            "Epoch 16/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3279 - val_loss: 0.3693\n",
            "Epoch 17/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3393 - val_loss: 0.3500\n",
            "Epoch 18/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3310 - val_loss: 0.3223\n",
            "Epoch 19/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3221 - val_loss: 0.3257\n",
            "Epoch 20/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3297 - val_loss: 0.3706\n",
            "Epoch 21/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3197 - val_loss: 0.3249\n",
            "Epoch 22/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3271 - val_loss: 0.3342\n",
            "Epoch 23/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3279 - val_loss: 0.3186\n",
            "Epoch 24/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3561 - val_loss: 0.3172\n",
            "Epoch 25/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3123 - val_loss: 0.3162\n",
            "Epoch 26/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3233 - val_loss: 0.3302\n",
            "Epoch 27/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3185 - val_loss: 0.3212\n",
            "Epoch 28/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3134 - val_loss: 0.3166\n",
            "Epoch 29/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3106 - val_loss: 0.3274\n",
            "Epoch 30/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3213 - val_loss: 0.3442\n",
            "Epoch 31/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3070 - val_loss: 0.3188\n",
            "Epoch 32/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3290 - val_loss: 0.3131\n",
            "Epoch 33/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3035 - val_loss: 0.3204\n",
            "Epoch 34/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3275 - val_loss: 0.3352\n",
            "Epoch 35/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3032 - val_loss: 0.3235\n",
            "Epoch 36/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.5252 - val_loss: 0.3457\n",
            "Epoch 37/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3075 - val_loss: 0.3157\n",
            "Epoch 38/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3104 - val_loss: 0.3486\n",
            "Epoch 39/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3142 - val_loss: 0.3083\n",
            "Epoch 40/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3113 - val_loss: 0.3323\n",
            "Epoch 41/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3108 - val_loss: 0.3084\n",
            "Epoch 42/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3033 - val_loss: 0.3219\n",
            "Epoch 43/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3160 - val_loss: 0.3190\n",
            "Epoch 44/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3004 - val_loss: 0.3092\n",
            "Epoch 45/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3024 - val_loss: 0.3078\n",
            "Epoch 46/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3005 - val_loss: 0.3045\n",
            "Epoch 47/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.2994 - val_loss: 0.3178\n",
            "Epoch 48/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2965 - val_loss: 0.3023\n",
            "Epoch 49/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3253 - val_loss: 0.3058\n",
            "Epoch 50/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3100 - val_loss: 0.3191\n",
            "Epoch 51/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.2972 - val_loss: 0.3466\n",
            "Epoch 52/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3229 - val_loss: 0.3074\n",
            "Epoch 53/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2936 - val_loss: 0.3104\n",
            "Epoch 54/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3054 - val_loss: 0.3094\n",
            "Epoch 55/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.2953 - val_loss: 0.3096\n",
            "Epoch 56/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.2959 - val_loss: 0.3284\n",
            "Epoch 57/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.2953 - val_loss: 0.3248\n",
            "Epoch 58/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2944 - val_loss: 0.3024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f5f74e13f28>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgOUksv-gL4F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# we can define our own call backs\n",
        "class mycallback(keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epochs, logs):\n",
        "    if(logs.get('accuracy')> 0.99):\n",
        "      print(\"Reached 99% accuracy\")\n",
        "      self.model.stop_training = True"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kOFmyCkhHUv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "callback = mycallback()\n",
        "model.fit(callbacks = [callback])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}